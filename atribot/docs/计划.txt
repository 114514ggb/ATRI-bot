Context condensed
目前的群聊天情况对于大多数情况(就是日常聊天任务，面对对话中有价值的信息量严重不足情况)，我一直采用的是直接截断丢弃的方案
开始考虑加入到指定条件后进行上下文压缩的功能了,可在有长关联性对话保持记忆

Context Memory tool 
对于前面的被丢弃的上下文应该，也进行存储，虽然请求时不会携带
因为上面的Context condensed仅仅时进行了总结，可能会顺损失重要的细节部分
对于目前的这个情况就需要模型能主动查询丢弃的上下文了
当然或许也可以支持模型可以编辑管理自己的上下文,自己控制哪些要删除哪些要留,哪些要总结来解决这些问题(?)

Programmatic tool calling
对于json交互还是有些许问题
最好能采用编程的方式进行发言，和搜索什么的
模型可以直接编写带有条件或循环的代码来处理数据或发送消息(比如你让LLM从1数到100可以通过循环来调用发消息的方法来一次性实现,但是也需要相应的限制)
模型应不应直接和user交互,而是通过编写代码，再由执行代码解释器执行，给出结果

Tool search tool 
 对LLM不直接暴露所有工具,但是会有一个用于查找其余工具的tool,查找后会在下一次请求中携带满足条件的工具
对于查询条件可以使用正则表达式或是对自然语言向量化筛选出语义相近的工具
但是为了保证模型不会做什么都去搜索(因为模型不知道他有什么工具不知道能干什么)，需要在上下文中嵌入拥有工具的概况
对于搜索到的工具存在的时间应该是一轮(从一次user输入,到模型给出完全满足需要的答案了就是一轮)
对于工具的筛选也有很多方案,比如可以根据用户输入，动态给出可能使用工具,不需要LLM直接查询

